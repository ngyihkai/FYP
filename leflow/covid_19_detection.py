# -*- coding: utf-8 -*-
"""covid-19 detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HT3jj4YPhHkKrRZn_u2bHgqke-MSFqJQ
"""
import os
from git.repo.base import Repo
Repo.clone_from("https://github.com/ieee8023/covid-chestxray-dataset.git", "folderToSave")

##! git clone https://github.com/ieee8023/covid-chestxray-dataset.git
# Datasset:

import requests
url = "http://cb.lk/covid_19"
r = requests.get(url)
##!wget http://cb.lk/covid_19
##!unzip covid_19

import pandas as pd
import os
import shutil

#create a data for positve samples
FILE_PATH = "/content/covid-chestxray-dataset/metadata.csv"
IMAGES_PATH = "/content/covid-chestxray-dataset/images"

df = pd.read_csv(FILE_PATH)
print(df.shape)
len(os.listdir(IMAGES_PATH))

df.head()

TARGET_DIR = "/content/Dataset/Covid"

if not os.path.exists(TARGET_DIR):
  os.mkdir(TARGET_DIR)
  print ("Covid folder created")

new_menu = ['No Finding', 'Pneumonia/Bacterial/Legionella', 'Pneumonia/Viral/COVID-19', 'Pneumonia', 'Pneumonia/Viral/Influenza', 'Pneumonia/Bacterial/Streptococcus', 'Pneumonia/Bacterial/Staphylococcus/MRSA', 'Tuberculosis', 'Pneumonia/Bacterial/Klebsiella', 'todo', 'Pneumonia/Viral/MERS-CoV','Pneumonia/Bacterial/Nocardia','Pneumonia/Fungal/Pneumocystis', 'Pneumonia/Aspiration','Pneumonia/Fungal/Aspergillosis','Pneumonia/Lipoid']

final_new_menu = list(dict.fromkeys(new_menu))

print(final_new_menu)

"""intubation:插管法
The posteroanterior (PA) chest view examines the lungs, bony thoracic cavity, mediastinum and great vessels.
"""

# covid-19 file
cnt = 0

for (i,row) in df.iterrows():
  if row["finding"]=="Pneumonia/Viral/COVID-19" and row["view"]=="PA":
    filename = row["filename"] 
    image_path = os.path.join(IMAGES_PATH,filename)
    image_copy_path = os.path.join(TARGET_DIR,filename)
    shutil.copy2(image_path,image_copy_path)
    #print("Moving image", cnt)
    cnt +=1

print(cnt)
len(os.listdir(TARGET_DIR))

# Sampling of Images from Kaggle
# 50% covid images and 50% normal images
import random
KAGGLE_FILE_PATH = "/content/CovidDataset/Train/Normal"
TARGET_NORMAL_DIR = "/content/Dataset/Normal"

image_names = os.listdir(KAGGLE_FILE_PATH)
len(os.listdir(KAGGLE_FILE_PATH))

image_names

random.shuffle(image_names)

for i in range(111): #from 0 to 111
  image_name = image_names[i]
  image_path = os.path.join(KAGGLE_FILE_PATH, image_name)

  target_path = os.path.join(TARGET_NORMAL_DIR,image_name)
  shutil.copy2(image_path, target_path)
  #print("Copying image", i)

TRAIN_PATH = "/content/CovidDataset/Train"
VAL_PATH = "/content/CovidDataset/Test"
print(f'\n{os.listdir(TRAIN_PATH)}, {os.listdir(test_dir)}, {os.listdir(VAL_PATH)}')

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.layers import *
from keras.models import *
from keras.preprocessing import image

# CNN Based Model in Keras

model = Sequential ()
model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(224,224,3))) #32=filter/layers, 224 width, height, 3=inputchannel
model.add(Conv2D(64,(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(64,(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(128,(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1,activation='sigmoid'))

model.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics=['accuracy'])

#For Dense Layers:
#output_size * (input_size + 1) == number_parameters 
#For Conv Layers:
#output_channels * (input_channels * window_size + 1) == number_parameters
model.summary()

"""1.   conv2d_4 (Conv2D): 32*(3channel*(3x3)+1)
2.   conv2d_5 (Conv2D): 64*(32channel*(3x3)+1)
3.   conv2d_6 (Conv2D): 64*(64channel*(3x3)+1)
4.   conv2d_7 (Conv2D): 128*(64channel*(3x3)+1)
5.   dense_3 (Dense): 64output*(86528+1)
6.   dense_3 (Dense): 1output*(64+1)
7.   flatten layer:input = output data
"""

# Train from scratch
train_datagen = image.ImageDataGenerator(
    rescale = 1./255,
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True,
)

test_dataset = image.ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    '/content/CovidDataset/Train',
    target_size = (224,224),
    batch_size = 32,
    class_mode = 'binary')

train_generator.class_indices

validation_generator = test_dataset.flow_from_directory(
    '/content/CovidDataset/Val',
    target_size = (224,224),
    batch_size =32,
    class_mode = 'binary'
)

hist = model.fit_generator(
    train_generator,
    steps_per_epoch=8,
    epochs =10,
    validation_data = validation_generator,
    validation_steps=2
)

# class activation maps
# grad-CAM

"""Loss is very less"""

#https://www.tensorflow.org/guide/keras/save_and_serialize
model.save("model_adv.h5")

model.evaluate_generator(train_generator)

model.evaluate_generator(validation_generator)

"""Test Images"""

model = load_model('model_adv.h5')

import os

train_generator.class_indices

y_actual = []
y_test = []

for i in os.listdir("/content/CovidDataset/Val/Covid/"):
  img = image.load_img("/content/CovidDataset/Val/Covid/"+i, target_size=(224,224))
  img = image.img_to_array(img)
  img = np.expand_dims(img,axis=0)
  predictions = (model.predict((img)))
  y_test.append(predictions[0,0])
  y_actual.append(1)

for i in os.listdir("/content/CovidDataset/Val/Covid/"):
  img = image.load_img("/content/CovidDataset/Val/Covid/"+i, target_size=(224,224))
  img = image.img_to_array(img)
  img = np.expand_dims(img,axis=0)
  predictions = (model.predict((img)))
  y_test.append(predictions[0,0])
  y_actual.append(0)

y_actual = np.array(y_actual)
y_test = np.array(y_test)

"""Confusion matrix"""

from sklearn.metrics import confusion_matrix

#y_test:predicted
cm = confusion_matrix (y_actual, y_test)

# classification report for precision, recall f1-score and accuracy
group_names = [‘True Neg’,’False Pos’,’False Neg’,’True Pos’]
group_counts = [“{0:0.0f}”.format(value) for value in
                cf_matrix.flatten()]
group_percentages = [“{0:.2%}”.format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f”{v1}\n{v2}\n{v3}” for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
matrix = classification_report(y_actual,y_test,labels=[1,0])
print('Classification report : \n',matrix)

"""Heatmap"""

import seaborn as sns

sns.heatmap(cm, cmap="plasma", annot=True)
